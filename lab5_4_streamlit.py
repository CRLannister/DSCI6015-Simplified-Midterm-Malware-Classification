import json
import boto3
import streamlit as st
import pandas as pd
from sklearn.metrics import confusion_matrix
from scipy.sparse import load_npz

def classify(payload_data):
    client = boto3.client('sagemaker-runtime')
    endpoint_name = 'sagemaker-scikit-learn-2024-03-27-07-07-48-860'
    content_type = 'application/json'  # The MIME type of the input data in the request body.
    accept = 'application/json'  # The desired MIME type of the inference in the response.
    response = client.invoke_endpoint(
        EndpointName=endpoint_name,
        ContentType=content_type,
        Accept=accept,
        Body=payload_data
    )

    response_body = response['Body'].read().decode('utf-8')
    response_data = json.loads(response_body)

    return response_data

# Set the page configuration for better resolution
st.set_page_config(page_title="Classification Results", layout="wide")

# Create Streamlit app
st.title('Sagemaker Endpoint Classifier')

# File uploader for uploading files
uploaded_files = st.file_uploader("Upload a npz and json label File" , accept_multiple_files=True)

number = st.number_input("Enter a number of samples between 1 and 234 (For quick demo choose small value)", min_value=1, max_value=234, step=1)

if uploaded_files:
    # Display uploaded file name
    st.text("Uploaded files:")
    file_names = [file.name for file in uploaded_files]
    st.text(', '.join(file_names))

    # Button to classify
    if st.button("Classify"):
        # Load data from the uploaded file
        # Initialize the index variable to None
        npz_index = None
        json_index = None
        y_pred = []

        # Iterate through the list
        for i, element in enumerate(file_names):
            # Check if the element ends with ".npz"
            if element.endswith(".npz"):
                # If found, store the index
                npz_index = i
            else:
                json_index = i

        #X_test = load_npz(file_names[npz_index])
        X_test = load_npz(uploaded_files[npz_index])
        y_true = json.loads(uploaded_files[json_index].read().decode('utf-8'))['results']
        #y_true = open(uploaded_files[json_index], 'r').read()

        if number > len(y_true):
            number = len(y_true)

        for i in range(number):
            payload = {"inputs": X_test.toarray()[i].tolist(), "results":[y_true[i]]}

            # Perform classification
            result = classify(json.dumps(payload))["y_pred"][0]

            # Extract predicted labels
            y_pred.append(result)

        # Calculate confusion matrix
        confusion_mat = confusion_matrix(y_true[:number], y_pred)

        # Display confusion matrix
        st.title("Confusion Matrix")
        st.write(confusion_mat)

        # Display classification results
        st.title("Classification Results")
        df = pd.DataFrame(zip(y_true[:number], y_pred), columns=["True Label", "Predicted Label"])
        st.dataframe(df.style.set_properties(**{'text-align': 'left'}), height=500)
